# -*- coding: utf-8 -*-
"""
Python File Template 
"""

import os
import numpy as np
import pandas as pd
import pickle
import json

import xml.etree.ElementTree

import re

__author__ = "Rui Meng"
__email__ = "rui.meng@pitt.edu"

ROOT_PATH = "/Users/memray/Project/upmc_wsd/wsd_data/mimic/"

# A very complete UMLS thesaurus providing sense unique id, many longform variants and a few abbreviations
UMLS_sense_file_path = '/Users/memray/Project/upmc_wsd/wsd_data/mimic/MRCONSO.RRF'
# A sense inventory generated by ADAM method based on MEDLINE paper data, containing a lot of noise
MEDLINE_sense_xml_path = os.path.join(ROOT_PATH, 'normalized_abbr_sense2.xml')

# A sense inventory by merging both UMLS and MEDLINE
UMLS_OR_MEDLINE_sense_inventory_path = os.path.join(ROOT_PATH, 'umls_or_medline_sense_inventory.pkl')
# A filtered UMLS sense inventory by only retaining senses appearing in MEDLINE
UMLS_AND_MEDLINE_sense_inventory_path = os.path.join(ROOT_PATH, 'umls_and_medline_sense_inventory.pkl')

# A cleaned sense inventory used for further filtering.
# provided by Zhendong used for annotation, for each sense only one abbr and one longform are provided
CLEANED_SENSE_inventory_csv_path = os.path.join(ROOT_PATH, 'sense_inventory_cleaned_annotation.csv')

# output file path
FINAL_CLEANED_SENSE_INVENTORY_PICKLE_PATH = os.path.join(ROOT_PATH, 'final_cleaned_sense_inventory.pkl')
FINAL_CLEANED_SENSE_INVENTORY_JSON_PATH = os.path.join(ROOT_PATH, 'final_cleaned_sense_inventory.json')

ABBR_WHITELIST = {'CPT 1', '4 ASA', 'HSAN 3', 'HSAN III',
                  'Epi DX', 'MEN 2B', 'CRPS I', 'DIN 1B',
                  'EC Tab', 'Ad Lib', 'EC Cell', 'CHF NOS',
                  'MEN IIB', 'Q fever', 'Vag Tab', 'AS ODNs',
                  'MPS I H', 'IV DRIP', 'Burn NOS', 'PEG 8O00',
                  'Chew Tab', 'TAB CHEW', 'MOAB LL2', 'Vag Supp',
                  '4\'-epi DX', 'MoAb CD52', 'MOAB HER2', 'MoAb VEGF',
                  'TAB EFFRV', 'DEXA scan', 'rHuIFN-a 2a', 'Tc-99m MIBI',
                  'rhuMAb HER2', 'dThdPase', 'RARalpha', 'RARgamma'}

class Sense():
    def __init__(self, cui):
        self.cui = cui
        self.abbr_set = set()
        self.longform_set = set()
        self.tty_list = []
        self.text_list = []

    def add_abbr(self, abbr):
        self.abbr_set.add(abbr)

    def add_longform(self, longform):
        self.longform_set.add(longform)

    def add_tty(self, tty):
        self.tty_list.append(tty)

    def add_text(self, text):
        self.text_list.append(text)

    def __str__(self):
        retune_str = 'CUI: %s\n' % (self.cui)
        for tty, text in zip(self.tty_list, self.text_list):
            retune_str += '\t%s: %s\n' % (tty, text)
        return retune_str

    def to_dict(self):
        sense_dict = {'CUI': self.cui, 'ABBR': list(self.abbr_set), 'LONGFORM': list(self.longform_set)}
        return sense_dict


def load_umls_senses(umls_thesaurus_path = UMLS_sense_file_path):
    umls_names = ["CUI", "LAT", "TS", "LUI", "STT", "SUI", "ISPREF", "AUI", "SAUI", "SCUI", "SDUI", "SAB", "TTY", "CODE", "STR", "SRL", "SUPPRESS", "256"]
    umls_df = pd.read_csv(umls_thesaurus_path, chunksize=100000, sep='|', header=None, names=umls_names, index_col=False)

    umls_sense_dict = {}

    for chunk in umls_df:
        for _, row in chunk.iterrows():
            cui = row['CUI']
            tty = row['TTY']
            text = row['STR']

            if cui not in umls_sense_dict:
                sense = Sense(cui = cui)
            else:
                sense = umls_sense_dict[cui]

            try:
                if tty.endswith('AB'):
                    sense.add_abbr(text)
                else:
                    sense.add_longform(text)

                umls_sense_dict[cui] = sense
            except Exception as e:
                print(cui)
                print(tty)
                print(text)
                print(str(e)+'\n')

    return umls_sense_dict


def load_medline_abbr_dict(sense_xml_path=MEDLINE_sense_xml_path):
    """
    Load the senses extracted from MEDLINE (by ADAM method)
    Each abbr corresponds to many longforms
     But each longform may appear in many abbr groups as well
    :return:
    abbr_long_dict, key is an abbr, value is a list of corresponding longforms
    long_abbr_dict, key is a longform, value is a list of corresponding abbrs
    long_list, a list of all longforms
    """
    # create element tree object
    tree = xml.etree.ElementTree.parse(sense_xml_path)

    # get root element
    root = tree.getroot()

    # create empty list for news items
    abbr_long_dict = {}
    long_abbr_dict = {}
    long_list = []

    # iterate news items
    for abbr in root:
        short_form = abbr.attrib['name']

        # empty news dictionary
        long_forms = []

        # iterate child elements of item
        for sense in abbr:
            # print('\t%s' % sense.attrib['normalized_name'])
            long_form = sense.attrib['normalized_name'].lower().strip()
            long_forms.append(long_form)

            for alternative in sense:
                # print('\t\t%s' % alternative.text)
                long_form = alternative.text.lower().strip()
                long_forms.append(long_form)

        abbr_long_dict[short_form] = long_forms
        for long_form in long_forms:
            long_list.append(long_form)
            abbr_list = long_abbr_dict.get(long_form, [])
            abbr_list.append(short_form)
            long_abbr_dict[long_form] = list(set(abbr_list))

    print('#(abbr_long_dict) = %d' % len(abbr_long_dict))
    print('#(long_abbr_dict) = %d' % len(long_abbr_dict))
    print('#(long_list) = %d' % len(long_list))

    return abbr_long_dict, long_abbr_dict, long_list


def load_sense_inventory():
    abbr_long_dict, long_abbr_dict, long_list = load_medline_abbr_dict()
    umls_sense_inventory_dict = load_umls_senses()

    print('Stats of UMLS sense inventory (before merging medline)')
    print('#(sense) = %d' % len(umls_sense_inventory_dict))
    print('#(abbr) = %d' % np.sum([len(s.abbr_set) for s in umls_sense_inventory_dict.values()]))
    print('#(long form) = %d' % np.sum([len(s.longform_set) for s in umls_sense_inventory_dict.values()]))

    # only keep the senses that appear in MEDLINE (related to medical and clinical)
    umls_and_medline_sense_inventory_dict = {}

    for sense_id, sense in umls_sense_inventory_dict.items():
        # iterate each longform appears in UMLS
        umls_longforms = list(sense.longform_set)
        for umls_longform in umls_longforms:
            # check if it appears in medline
            if umls_longform in long_abbr_dict:
                # add corresponding abbr to current sense
                for medline_abbr in long_abbr_dict[umls_longform]:
                    sense.add_abbr(medline_abbr)
                    # (deprecated, add too much noise) add all longforms corresponding to this abbr to this sense as well
                    # for medline_longform in abbr_long_dict[medline_abbr]:
                    #     sense.add_longform(medline_longform)

                umls_and_medline_sense_inventory_dict[sense.cui] = sense


    print('Stats of sense inventory (merging UMLS and medline)')
    print('#(sense) = %d' % len(umls_sense_inventory_dict))
    print('#(abbr) = %d' % np.sum([len(s.abbr_set) for s in umls_sense_inventory_dict.values()]))
    print('#(long form) = %d' % np.sum([len(s.longform_set) for s in umls_sense_inventory_dict.values()]))

    print('Stats of valid sense inventory (appear both in UMLS and medline)')
    print('#(sense) = %d' % len(umls_and_medline_sense_inventory_dict))
    print('#(abbr) = %d' % np.sum([len(s.abbr_set) for s in umls_and_medline_sense_inventory_dict.values()]))
    print('#(long form) = %d' % np.sum([len(s.longform_set) for s in umls_and_medline_sense_inventory_dict.values()]))

    return umls_sense_inventory_dict, umls_and_medline_sense_inventory_dict


def build_sense_inventory():
    umls_sense_dict, umls_and_medline_sense_inventory_dict = load_sense_inventory()

    with open(UMLS_OR_MEDLINE_sense_inventory_path, 'wb') as sense_file:
        pickle.dump(umls_sense_dict, sense_file)

    with open(UMLS_AND_MEDLINE_sense_inventory_path, 'wb') as sense_file:
        pickle.dump(umls_and_medline_sense_inventory_dict, sense_file)

    return umls_and_medline_sense_inventory_dict


def load_UMLS_and_MEDLINE_sense_inventory_from_disk():
    with open(UMLS_AND_MEDLINE_sense_inventory_path, 'rb') as sense_file:
        umls_and_medline_sense_dict = pickle.load(sense_file)

    return umls_and_medline_sense_dict


def filter_by_CUI_cleaned(sense_inventory_dict):
    """
    The senses for annotation has been cleaned once, therefore we use its CUIs to filter our senses
    """
    cleaned_sense_for_annotation_df = pd.read_csv(CLEANED_SENSE_inventory_csv_path)
    cui_to_keep = set(cleaned_sense_for_annotation_df['id'].tolist())

    filtered_sense_inventory_dict = {}
    for k,v in sense_inventory_dict.items():
        if k in cui_to_keep:
            filtered_sense_inventory_dict[k] = v

    print('Stats of sense inventory (after filtering by the senses for annotation)')
    print('#(sense) = %d' % len(filtered_sense_inventory_dict))
    print('#(abbr) = %d' % np.sum([len(s.abbr_set) for s in filtered_sense_inventory_dict.values()]))
    print('#(long form) = %d' % np.sum([len(s.longform_set) for s in filtered_sense_inventory_dict.values()]))

    return filtered_sense_inventory_dict


def clean_abbrs(sense_inventory_dict):
    """
    Many abbrs are not valid (longform)
    :param sense_dict:
    :return:
    """
    sense_with_valid_abbr_count = 0
    false_abbr_list = []

    for cui, sense in sense_inventory_dict.items():
        new_abbr_set = set()
        for abbr in sense.abbr_set:
            if len(re.split(r'[\s\[\]\{\}]+', abbr)) > 1 \
                    and abbr not in ABBR_WHITELIST \
                    and not abbr.lower().endswith(' nos')\
                    and not abbr.lower().startswith('moab '):
                false_abbr_list.append(abbr)
                continue

            if len(abbr.strip()) == 0:
                false_abbr_list.append(abbr)
                continue

            if len(abbr) > 7 \
                    and abbr not in ABBR_WHITELIST \
                    and not abbr.lower().endswith(' nos')\
                    and not abbr.lower().startswith('moab ')\
                    and len(re.split(r'\W+', abbr)) == 1:
                false_abbr_list.append(abbr)
                continue

            new_abbr_set.add(abbr.strip())

        sense.abbr_set = new_abbr_set

        if len(sense.abbr_set) > 0:
            sense_with_valid_abbr_count += 1

    # false_abbr_list = sorted(false_abbr_list, key=lambda x: len(x))
    # for abbr in false_abbr_list:
    #     print("'%s', " % abbr)

    print('#(senses w/ abbr)/#(all senses) = %d/%d' % (sense_with_valid_abbr_count, len(sense_inventory_dict)))

    return sense_inventory_dict


def output_to_pickle_and_json(sense_inventory_dict):
    with open(FINAL_CLEANED_SENSE_INVENTORY_JSON_PATH, 'w') as sense_json:
        for sense in sense_inventory_dict.values():
            sense_dict = sense.to_dict()
            sense_json.write(json.dumps(sense_dict) + '\n')

    with open(FINAL_CLEANED_SENSE_INVENTORY_PICKLE_PATH, 'wb') as sense_pickle:
        pickle.dump(sense_inventory_dict, sense_pickle)


def clean_longforms(sense_inventory_dict):
    """
    some longforms are duplicates of abbr, remove them
    some longforms have irrelevant contents, such as (substance), remove these contents
    :param sense_inventory_dict:
    :return:
    """
    for sense in sense_inventory_dict.values():
        lower_abbr_set = set([abbr.lower() for abbr in sense.abbr_set])
        new_longform_set = set()

        for longform in sense.longform_set:
            new_longform = longform
            while re.search(r'^\[.*?\]| \(.*?\)$| \[.*?\]$| \{.*?\}$', new_longform) and len(new_longform) < 50:
                new_longform = re.sub(r'^\[.*?\]| \(.*?\)$| \[.*?\]$| \{.*?\}$','', new_longform).strip()
                # print(longform+ '\t->\t' + new_longform)

            if new_longform.lower().strip() in lower_abbr_set:
                # print('abbr-like longform: %s' % new_longform)
                continue

            if len(new_longform) > 0:
                new_longform_set.add(new_longform)

        sense.longform_set = new_longform_set

    print('Stats of sense inventory (after clearning abbr and longform)')
    print('#(sense) = %d' % len(sense_inventory_dict))
    print('#(abbr) = %d' % np.sum([len(s.abbr_set) for s in sense_inventory_dict.values()]))
    print('#(long form) = %d' % np.sum([len(s.longform_set) for s in sense_inventory_dict.values()]))

    return sense_inventory_dict


def load_final_sense_inventory():
    """
    Load the final sense inventory from disk, other than that, we also return a dict that use longform as key
    :return:
    """
    with open(FINAL_CLEANED_SENSE_INVENTORY_PICKLE_PATH, 'rb') as sense_pickle:
        sense_inventory_dict = pickle.load(sense_pickle)

    long_sense_dict = {}
    for sense in sense_inventory_dict.values():
        for longform in sense.longform_set:
            if longform in long_sense_dict:
                print('Conflicted sense: %s' % long_sense_dict[longform])
                print('Current sense: %s' % sense)
                print('-' * 30)
            long_sense_dict[longform] = sense

    return sense_inventory_dict, long_sense_dict


if __name__ == '__main__':
    # filtered_sense_dict = build_sense_inventory()
    sense_inventory_dict = load_UMLS_and_MEDLINE_sense_inventory_from_disk()
    sense_inventory_dict = filter_by_CUI_cleaned(sense_inventory_dict)
    sense_inventory_dict = clean_abbrs(sense_inventory_dict)
    sense_inventory_dict = clean_longforms(sense_inventory_dict)

    output_to_pickle_and_json(sense_inventory_dict)

